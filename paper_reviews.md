# Table of Contents
[Meta-analysis of tumor- and T cell-intrinsic mechanisms of sensitization to checkpoint inhibition](#meta-analysis-of-tumor--and-T-cell-intrinsic-mechanisms-of-sensitization-to-checkpoint-inhibition)

[A review of author name disambiguation techniques for the PubMed bibliographic database](#a-review-of-author-name-disambiguation-techniques-for-the-pubmed-bibliographic-database)

[Statistics versus machine learning](#statistics-versus-machine-learning)
<!---toc--->



# Meta-analysis of tumor- and T cell-intrinsic mechanisms of sensitization to checkpoint inhibition
PMID: [33508232](https://pubmed.ncbi.nlm.nih.gov/33508232/)

First and last authors: Kevin Litchfield, Charles Swanton
##### Main points
1. CPI1000+: 1008 CPI-treated (CTLA-4, PD-1, PD-L1)tumors from 12 individual cohorts from 7 tumor types (met uorthelial, melanoma, HNSCC, NSCLC, RCC, CRC, BRCA)
2. Benchmarked 55 biomarkers across 723 articles (includes TMB, tobacco mut, UV sig, etc). Z score standardized mutations and expression for comparison.
3. Clonal TMB strongest biomarker (estimated per cell mutation #)
4. All measured biomarkers only account for 60% of the variation, so 40% left undiscovered.
5. XGBoost to derive single score of biomarkers that achieved significance (11). Compared score to FDA-approved TMB biomarker. 3 test cohorts not in CPI1000+. Better AUC across all test cohorts compared to TMB.
6. CXCL9 expression and clonal TMB performs better than TMB alone.
7. COSMIC mutational signatures v2: 1A_aging, 4_tobacco, 7_UV, 10_POLE, 2_13_APOBEC were significant
8. Loss of 9q34 was associated with sensitization - TRAF2 gene is important. Selective pressure comes from other genes on chr9, including CDKN2A
9. CCND1 amplification associated with CPI resistance

# A review of author name disambiguation techniques for the PubMed bibliographic database

[Article link](https://journals.sagepub.com/doi/full/10.1177/0165551519888605?casa_token=kIW_km4OtaoAAAAA%3AzGXblIrEvk8RCOqVCQ_401mD5J0rasgpq0v7RlXetAri640TU994wWUO2eAhzzQldLDYkULB4Or7) 

## Main points

1. Problem definition
    1. Records contain at least title and author list
    2. Email, affiliation, venue, abstract, keywords, MeSH terms
    3. S={s_1, ..., s_N} into set of M(<=N) clusters C={C_1, ..., C_M} so each cluster C_i contains all and only all references to same real-world author
2. Evaluation measures used in literature: Sub-definitions
    1. TP = total number of pairs correctly assigned to same cluster
    2. TN = total number of pairs correctly assigned to different clusters
    3. FP = total number of pairs incorrectly assigned to same cluster
    4. FN = total number of pairs incorrectly assigned to different clusters
    5. S = TP + TN + FP + FN
    6. M_gold = number of manually generated true author-individual clusters
    7. M_cor = number of completely correct clusters generated by AND algo
    8. M_gen = total number of clusters generated by AND algo
    9. N = number of author references in dataset
    10. n_{ij} = total number of references in algo generated cluster i belonging to corresponding manual generated cluster j
    11. n_{i} = total number of references in automatically generated cluster i
    12. Set of author references S = {s_1, ..., s_N} partitioned into set of clusters V = {V_1, ..., V_v} by AND algo
    13. True (manually generated) set of disjoint author-individual clusters C = {C_1, ..., C_c}
    13. V(s_i) is automatically generated cluster to which s_i belongs
    14. C(s_i) is manually generated cluster to which s_i belongs
3. Evaluation measures used in literature: Definitions
    1. `Accuracy = (TP + TN)/S`
    2. Pairwise precision: `pp = TP/(TP + FP)`
        1. Fraction of pairs in cluster being  co-referent
        2. (Precision)[https://en.wikipedia.org/wiki/Precision_and_recall] = True positives per predicted positive
    3. Pairwise recall: `pr = TP/(TP + FN)`
        1. Fraction of co-referent pairs put into same cluster
        2. (Recall)[https://en.wikipedia.org/wiki/Precision_and_recall] = True positives per real positive
    4. Pairwise F1-score: `pf1 = (2 X pp X pr)/(ppp + pr)`
        1. [Harmonic mean of pp and pr](https://en.wikipedia.org/wiki/Harmonic_mean#In_other_sciences)
    5. Pairwise lumping error rate `PLER = FP/(TP/FP)`
        1. Fraction of pairs in cluster being non co-referent
    6. Pairwise splitting error rate `PSER = FN/(TN + FN)`
        1. Fraction of co-referent pairs split into different clusters
    7. Overall pairwise error rate `PER = (FP + FN)/S`
        1. Or `PER = PLER X clustering prob + PSER X unclustering prob`
        2. `Clustering prob = (TP + FP)/S`
        3. `Unclustering prob = (TN + FN)/S`
    8. Cluster precision `cp = M_cor/M_gen`
        1. Fraction of correct clusters/total generated clusters
    9. Cluster recall `cr = M_cor/M_gold`
        1. Fraction of true clusters
    10. Cluster F1-score `cf1 = (2 X cp X cr)/(cp + cr)`
    11. Ratio of cluster size `RCS = M_gen/M_gold`
        1. Ratio of number of clusters produced to number of true clusters
    12. Average cluster purity ![f1]
    13. Average author purity ![f2]
    14. K-measure ![f3]
        1. Geometric mean of ACP and AAP
    15. Fraction of references in automatically generated cluster containing s_i that truly refer to the individual identified by s_i ![f4]
        1. B-CUBED precision is average precision of all author references in the dataset ![f5]
    16. Recall of reference s_i is ![f6]
        1. B-CUBED recall is average recall of all author references in the dataset ![f7]
    17. B-CUBED F1-score `bf1 = (2 x bp x br)/(bp + br)`

[f1]: https://chart.apis.google.com/chart?cht=tx&chl=ACP=\frac{1}{N}\sum_{i=1}^{i=M_{gen}}\sum_{i=1}^{j=M_{gold}}\frac{n_{ij}^2}{n_i}
[f2]: https://chart.apis.google.com/chart?cht=tx&chl=AAP=\frac{1}{N}\sum_{i=1}^{i=M_{gold}}\sum_{i=1}^{j=M_{gen}}\frac{n_{ij}^2}{n_i}
[f3]: https://chart.apis.google.com/chart?cht=tx&chl=K=\sqrt{ACP\times\\;AAP}
[f4]: https://chart.apis.google.com/chart?cht=tx&chl=p(s_i)=\frac{|s\in\\;V(s_i)\\;:\\;C(s)=C(s_i)|}{|V(s_i)|}
[f5]: https://chart.apis.google.com/chart?cht=tx&chl=bp=\frac{\sum_{s\in\\;S}^{}p(s)}{N}
[f6]: https://chart.apis.google.com/chart?cht=tx&chl=r(s_i)=\frac{|s\in\\;C(s_i)\\;:\\;V(s)=V(s_i)|}{|C(s_i)|}
[f7]: https://chart.apis.google.com/chart?cht=tx&chl=br=\frac{\sum_{s\in\\;S}^{}r(s)}{N}

## Ideas for the future

1. Feature learning to discover which features most prominently identify authors
    1. The tendency for author to include email, institution (presence/absence of information)
    2. How collaborative an author is
    3. Likelihood of author appearing last or second to last

# Statistics versus machine learning

PMID: [30100822](https://pubmed.ncbi.nlm.nih.gov/30100822/)

## Main points


